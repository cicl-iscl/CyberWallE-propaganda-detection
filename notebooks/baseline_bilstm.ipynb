{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VubK6qZQUmeM"
   },
   "source": [
    "# Challenges in NLP, WS19/20\n",
    "\n",
    "Blaschke Verena, ISCL MA<br/>\n",
    "Korniyenko Maxim, ISCL MA<br/>\n",
    "Tureski Sam, ML MA<br/>\n",
    "\n",
    "-----\n",
    "## Baseline model for Span Identification task\n",
    "-----\n",
    "\n",
    "The working process looks like the following:\n",
    "- Data preparation.\n",
    "- Creating the model.\n",
    "- Training the model.\n",
    "- Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "KSkNNNrI9ZxW",
    "outputId": "87ea03b3-a70c-4eda-eb41-7296d15088dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating the model\n",
    "from keras.layers import Bidirectional, CuDNNLSTM, Dense, Dropout, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Results analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttjmy-nhWB4r"
   },
   "source": [
    "#1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgRlLi2IAb3U"
   },
   "source": [
    "Reading the data from the file and storing it in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ORZhvz69htt"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-bio.tsv?token=AFDEFD7WXGQPGEJK6X5OB6C53AMEC'\n",
    "df = pd.read_csv(url, sep='\\t',names=[\"document_id\", \"sent_number\",\"idx_token_beginning\", \"idx_token_end\", \"token\",\"bio_label\"], quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHqbQCKKFjHo"
   },
   "source": [
    "Getting the data frame with sentences and saving tokens to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTMwJaN0Essg"
   },
   "outputs": [],
   "source": [
    "df_sents = df.groupby('sent_number')['token'].apply(list)\n",
    "df_sents = df_sents.to_frame()\n",
    "df_sents['sent_number'] = df_sents.index\n",
    "df_sents[\"sentences\"]= df_sents[\"token\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lps0UMtgGeuF"
   },
   "outputs": [],
   "source": [
    "sentence_list = df_sents[\"token\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4akrSXlF6Nk"
   },
   "source": [
    "Getting the data frame with labels and them to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRor6_kiFvc1"
   },
   "outputs": [],
   "source": [
    "df_labels = df.groupby('sent_number')['bio_label'].apply(list)\n",
    "df_labels = df_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pml6EzXRGiV2"
   },
   "outputs": [],
   "source": [
    "bio_sent_list = df_labels[\"bio_label\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFczOPG1O0go"
   },
   "source": [
    "## Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1W2oPTMG-n2"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-HxXV8BHMuA"
   },
   "source": [
    "#### Encoding features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCS3v6NgWkvO"
   },
   "source": [
    "Reading the glove embeddings from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "61OlM1uZHtMr",
    "outputId": "ead5a959-f736-4709-afb3-e0d8707c233a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6Ab1jvz0H6hV",
    "outputId": "7d95c31c-cede-4019-e84e-36a995d585dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "file_path = 'gdrive/My Drive/colab_projects/data/glove.6B.100d.txt'\n",
    "f = open(file_path)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOIFqkxbHJfm"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "# first create a matrix of zeros, this is our embedding matrix\n",
    "embedding_matrix = np.zeros([len(sentence_list), MAX_SEQUENCE_LENGTH, embedding_dim])\n",
    "# for each word in out tokenizer lets try to find that work in our w2v model\n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    for j, word in enumerate(sentence_list[i]):\n",
    "        if j > MAX_SEQUENCE_LENGTH:\n",
    "        #Split these longer sentences later\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # we found the word - add that words vector to the matrix\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            # doesn't exist, assign a random vector\n",
    "            embedding_matrix[i] = np.random.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nb1HZ4VGkDI"
   },
   "source": [
    "#### Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxuy8104Xpbm"
   },
   "outputs": [],
   "source": [
    "# the following parameters should be changed\n",
    "# if we switch back to three labels\n",
    "label2idx = {\"O\": [1, 0], \"I\": [0, 1], \"B\": [0, 1]}\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ee6N07KeGoZN"
   },
   "outputs": [],
   "source": [
    "# first create a matrix of zeros, this is our embedding matrix\n",
    "y = np.zeros([len(sentence_list), MAX_SEQUENCE_LENGTH, n_classes])\n",
    "# for each word in out tokenizer lets try to find that work in our w2v model\n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    for j, word in enumerate(bio_sent_list[i]):\n",
    "        if j < MAX_SEQUENCE_LENGTH:\n",
    "            y[i][j] = label2idx.get(word)\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuMc4OyuIgvc"
   },
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oR_IlvbMIgWl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embedding_matrix, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQntrhwhW0Lo"
   },
   "source": [
    "# 2. Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "KuzEvEcGI1xd",
    "outputId": "a2832ea5-0029-4f70-889f-19d5ef7098ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 30, 1024)          2514944   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 2)             2050      \n",
      "=================================================================\n",
      "Total params: 2,516,994\n",
      "Trainable params: 2,516,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True), input_shape=(MAX_SEQUENCE_LENGTH, embedding_dim)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-1dXcmbXCUc"
   },
   "source": [
    "# 3. Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "uJm_cXYpI_Qy",
    "outputId": "879f87a1-e591-4b81-aafb-1a82bfba113f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 12687 samples, validate on 1410 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "12687/12687 [==============================] - 9s 685us/step - loss: 0.2773 - categorical_accuracy: 0.9044 - val_loss: 0.2428 - val_categorical_accuracy: 0.9246\n",
      "Epoch 2/10\n",
      "12687/12687 [==============================] - 6s 510us/step - loss: 0.2598 - categorical_accuracy: 0.9136 - val_loss: 0.2366 - val_categorical_accuracy: 0.9247\n",
      "Epoch 3/10\n",
      "12687/12687 [==============================] - 6s 507us/step - loss: 0.2554 - categorical_accuracy: 0.9143 - val_loss: 0.2439 - val_categorical_accuracy: 0.9246\n",
      "Epoch 4/10\n",
      "12687/12687 [==============================] - 6s 510us/step - loss: 0.2528 - categorical_accuracy: 0.9146 - val_loss: 0.2472 - val_categorical_accuracy: 0.9229\n",
      "Epoch 5/10\n",
      "12687/12687 [==============================] - 6s 511us/step - loss: 0.2517 - categorical_accuracy: 0.9150 - val_loss: 0.2394 - val_categorical_accuracy: 0.9243\n",
      "Epoch 6/10\n",
      "12687/12687 [==============================] - 7s 513us/step - loss: 0.2490 - categorical_accuracy: 0.9155 - val_loss: 0.2421 - val_categorical_accuracy: 0.9224\n",
      "Epoch 7/10\n",
      "12687/12687 [==============================] - 7s 515us/step - loss: 0.2480 - categorical_accuracy: 0.9156 - val_loss: 0.2429 - val_categorical_accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "12687/12687 [==============================] - 6s 512us/step - loss: 0.2444 - categorical_accuracy: 0.9163 - val_loss: 0.2460 - val_categorical_accuracy: 0.9225\n",
      "Epoch 9/10\n",
      "12687/12687 [==============================] - 7s 514us/step - loss: 0.2422 - categorical_accuracy: 0.9169 - val_loss: 0.2542 - val_categorical_accuracy: 0.9226\n",
      "Epoch 10/10\n",
      "12687/12687 [==============================] - 7s 515us/step - loss: 0.2424 - categorical_accuracy: 0.9165 - val_loss: 0.2556 - val_categorical_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cav1kjGKJlF5"
   },
   "source": [
    "# 4. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwPw0MN_Jnn3"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeVF7DgmXP2U"
   },
   "source": [
    "Making the true and predicted labels flat for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-1p76d4K4Ut"
   },
   "outputs": [],
   "source": [
    "y_hat_flat = y_hat.reshape(-1, n_classes).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqBcyG64LUYo"
   },
   "outputs": [],
   "source": [
    "y_test_flat = y_test.reshape(-1, n_classes).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bSKHG3lrMfsV",
    "outputId": "415ef267-c1b5-4bde-d7e3-1f236e0052c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48639353028075866"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_hat_flat, y_test_flat, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrZ07ubESnL7"
   },
   "outputs": [],
   "source": [
    "target_names = [\"O\", \"I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "39VpcectNHec",
    "outputId": "32621dcd-9832-491b-a480-ec4c9337bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.91      1.00      0.95     42922\n",
      "           I       0.19      0.01      0.02      4088\n",
      "\n",
      "    accuracy                           0.91     47010\n",
      "   macro avg       0.55      0.50      0.49     47010\n",
      "weighted avg       0.85      0.91      0.87     47010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_flat, y_hat_flat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VGjjnyOHSQAl",
    "outputId": "309bf581-b0b1-4fb1-b96f-4472715009f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42738,   184],\n",
       "       [ 4045,    43]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test_flat, y_pred=y_hat_flat)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "baseline-bilstm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
