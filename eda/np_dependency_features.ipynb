{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "np_dependency_features.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2xeJJ73Z7aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6zyB2i9wOmP",
        "colab_type": "text"
      },
      "source": [
        "Add better visibiity when checking head of dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjbT7foUuQeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXQHvVuUZgcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_comments(filename, url=True):\n",
        "    if url:\n",
        "        comments = []\n",
        "        with urllib.request.urlopen(filename) as f:\n",
        "            for line in f:\n",
        "                if line.startswith(b'#'):\n",
        "                    comments.append(line.decode(\"utf-8\"))\n",
        "                else:\n",
        "                    break\n",
        "        return comments\n",
        "    with open(filename, 'r', encoding='utf8') as f:\n",
        "        commentiter = takewhile(lambda s: s.startswith('#'), f)\n",
        "        comments = list(commentiter)\n",
        "    return comments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0axNlxoyWLKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DEV_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/si-train%2Bdev.tsv?token=AFDEFDYJYM6MWY4A6C277HC6MUDX6'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feVeu1ioZS7V",
        "colab_type": "code",
        "outputId": "a7b5cdd6-c89e-433a-d1e0-bdeb8c404bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "comments = get_comments(TRAIN_DEV_URL)\n",
        "train_df = pd.read_csv(TRAIN_DEV_URL, sep='\\t', skiprows=len(comments), quoting=3)\n",
        "train_input = train_df.groupby('sent_id')['token'].apply(list).to_frame()\n",
        "train_labels = train_df.groupby('sent_id')['label'].apply(list).to_frame()\n",
        "print(train_df.head())\n",
        "print(train_input.head())\n",
        "print(list(train_df.columns))\n",
        "print(train_df.shape[0])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document_id  sent_id  token_start  token_end       token label  positive  \\\n",
            "0  111111111    1        0            4          Next        O     0.000000   \n",
            "1  111111111    1        5            11         plague      O     0.071429   \n",
            "2  111111111    1        12           20         outbreak    O     0.000000   \n",
            "3  111111111    1        21           23         in          O     0.000000   \n",
            "4  111111111    1        24           34         Madagascar  O     0.000000   \n",
            "\n",
            "   negative  arglex_any  ADJ  ADP  ADV  CCONJ  DET  INTJ  NOUN  NUM  PART  \\\n",
            "0  0.031250  0           1    0    0    0      0    0     0     0    0      \n",
            "1  0.214286  0           0    0    0    0      0    0     1     0    0      \n",
            "2  0.125000  0           0    0    0    0      0    0     1     0    0      \n",
            "3  0.000000  0           0    1    0    0      0    0     0     0    0      \n",
            "4  0.000000  0           0    0    0    0      0    0     0     0    0      \n",
            "\n",
            "   PRON  PROPN  PUNCT  SYM  VERB  X  \n",
            "0  0     0      0      0    0     0  \n",
            "1  0     0      0      0    0     0  \n",
            "2  0     0      0      0    0     0  \n",
            "3  0     0      0      0    0     0  \n",
            "4  0     1      0      0    0     0  \n",
            "                                                                                                                                                                                                                                                  token\n",
            "sent_id                                                                                                                                                                                                                                                \n",
            "1        [Next, plague, outbreak, in, Madagascar, could, be, ', stronger, ', :, WHO]                                                                                                                                                                   \n",
            "2        [Geneva, -, The, World, Health, Organisation, chief, on, Wednesday, said, a, deadly, plague, epidemic, appeared, to, have, been, brought, under, control, in, Madagascar, ,, but, warned, the, next, outbreak, would, likely, be, stronger, .]\n",
            "3        [\"\"\"\", The, next, transmission, could, be, more, pronounced, or, stronger, ,, \"\"\"\", WHO, Director, -, General, Tedros, Adhanom, Ghebreyesus, told, reporters, in, Geneva, ,, insisting, that, \"\"\"\", the, issue, is, serious, ., \"\"\"\"]         \n",
            "4        [An, outbreak, of, both, bubonic, plague, ,, which, is, spread, by, infected, rats, via, flea, bites, ,, and, pneumonic, plague, ,, spread, person, to, person, ,]                                                                            \n",
            "5        [has, killed, more, than, 200, people, in, the, Indian, Ocean, island, nation, since, August, .]                                                                                                                                              \n",
            "['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']\n",
            "468114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAD0jIZ5waKI",
        "colab_type": "text"
      },
      "source": [
        "Concatenate tokens back into sentences so we can parse their structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBc-dwzEnSsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "b592df10-bfd6-49b0-d6e5-6e8b2b52d6a6"
      },
      "source": [
        "sents_df = pd.DataFrame({'sent_id':train_input['token'].index, 'tokenized_sent':train_input['token'].values})\n",
        "sents_df[\"full_sents\"]= sents_df[\"tokenized_sent\"].str.join(\" \")\n",
        "print(sents_df.head())"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sent_id  \\\n",
            "0  1         \n",
            "1  2         \n",
            "2  3         \n",
            "3  4         \n",
            "4  5         \n",
            "\n",
            "                                                                                                                                                                                                                                   tokenized_sent  \\\n",
            "0  [Next, plague, outbreak, in, Madagascar, could, be, ', stronger, ', :, WHO]                                                                                                                                                                      \n",
            "1  [Geneva, -, The, World, Health, Organisation, chief, on, Wednesday, said, a, deadly, plague, epidemic, appeared, to, have, been, brought, under, control, in, Madagascar, ,, but, warned, the, next, outbreak, would, likely, be, stronger, .]   \n",
            "2  [\"\"\"\", The, next, transmission, could, be, more, pronounced, or, stronger, ,, \"\"\"\", WHO, Director, -, General, Tedros, Adhanom, Ghebreyesus, told, reporters, in, Geneva, ,, insisting, that, \"\"\"\", the, issue, is, serious, ., \"\"\"\"]            \n",
            "3  [An, outbreak, of, both, bubonic, plague, ,, which, is, spread, by, infected, rats, via, flea, bites, ,, and, pneumonic, plague, ,, spread, person, to, person, ,]                                                                               \n",
            "4  [has, killed, more, than, 200, people, in, the, Indian, Ocean, island, nation, since, August, .]                                                                                                                                                 \n",
            "\n",
            "                                                                                                                                                                                                    full_sents  \n",
            "0  Next plague outbreak in Madagascar could be ' stronger ' : WHO                                                                                                                                               \n",
            "1  Geneva - The World Health Organisation chief on Wednesday said a deadly plague epidemic appeared to have been brought under control in Madagascar , but warned the next outbreak would likely be stronger .  \n",
            "2  \"\"\"\" The next transmission could be more pronounced or stronger , \"\"\"\" WHO Director - General Tedros Adhanom Ghebreyesus told reporters in Geneva , insisting that \"\"\"\" the issue is serious . \"\"\"\"          \n",
            "3  An outbreak of both bubonic plague , which is spread by infected rats via flea bites , and pneumonic plague , spread person to person ,                                                                      \n",
            "4  has killed more than 200 people in the Indian Ocean island nation since August .                                                                                                                             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJb6HHWzw9aV",
        "colab_type": "text"
      },
      "source": [
        "Check to see if we have the same number of tokenized sentences and the now concatenated sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwamITlQBydG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a2ed929-029a-4da3-b612-8865bc480b53"
      },
      "source": [
        "sents_list = sents_df['tokenized_sent'].tolist()\n",
        "full_sents_list = sents_df['full_sents'].tolist()\n",
        "print(len(sents_list), len(full_sents_list))\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25310 25310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEosw-DPxGrc",
        "colab_type": "text"
      },
      "source": [
        "Iterate though the full sentences and get all the tokens in each sentence that exist in Noun Phrase chunks. Noun Phrase chunking is already provided by Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNJHGqeoNicm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_marked_tokens = []\n",
        "for count, sent in enumerate(full_sents_list):\n",
        "  doc = nlp(str(sent))\n",
        "  chunks_list = list(doc.noun_chunks)\n",
        "  tokens_in_sent = []\n",
        "  for chunk in chunks_list:\n",
        "    for token in chunk:\n",
        "      tokens_in_sent.append(token.text)\n",
        "  all_marked_tokens.append(tokens_in_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7msIhfUGxf7l",
        "colab_type": "text"
      },
      "source": [
        " Match the tokens in NP chunks to the pre-tokenized sentences, marking 1 for a match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmaMcGUkDGR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "99b6af4e-865a-46db-9580-aa8b6a0dd776"
      },
      "source": [
        "all_isin_np_list = []\n",
        "for count, sent in enumerate(sents_list):\n",
        "  isin_np_list = np.zeros(len(sent))\n",
        "  for i, word in enumerate(sent):\n",
        "    if word in all_marked_tokens[count]:\n",
        "      isin_np_list[i] = 1\n",
        "      all_marked_tokens[count].remove(word)\n",
        "  all_isin_np_list.append(isin_np_list)\n",
        "print(all_isin_np_list[0:5])\n",
        "print(len(all_isin_np_list))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]), array([1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.]), array([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]), array([1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
            "       0., 1., 1., 0., 0., 1., 0., 1., 0.]), array([0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])]\n",
            "25310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl283tFFjfu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ed2a49be-80a4-4a50-87e7-95bc655a4e76"
      },
      "source": [
        "np_list = [x.tolist() for x in all_isin_np_list]\n",
        "print(np_list[5:10])\n",
        "print(sents_list[5:10])\n",
        "print(full_sents_list[5:10])"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]]\n",
            "[['Madagascar', 'has', 'suffered', 'bubonic', 'plague', 'outbreaks', 'almost', 'every', 'year', 'since', '1980', ',', 'often', 'caused', 'by', 'rats', 'fleeing', 'forest', 'fires', '.'], ['The', 'disease', 'tends', 'to', 'make', 'a', 'comeback', 'each', 'hot', 'rainy', 'season', ',', 'from', 'September', 'to', 'April', '.'], ['On', 'average', ',', 'between', '300', 'and', '600', 'infections', 'are', 'recorded', 'every', 'year', 'among', 'a', 'population', 'approaching', '25', 'million', 'people', ',', 'according', 'to', 'a', 'UN', 'estimate', '.'], ['But', 'Tedros', 'voiced', 'alarm', 'that', '\"\"\"\"', 'plague', 'in', 'Madagascar', 'behaved', 'in', 'a', 'very', ',', 'very', 'different', 'way', 'this', 'year', '.', '\"\"\"\"'], ['Cases', 'sprang', 'up', 'far', 'earlier', 'than', 'usual', 'and', ',', 'instead', 'of', 'being', 'confined', 'to', 'the', 'countryside', ',', 'the', 'disease', 'infiltrated', 'towns', '.']]\n",
            "['Madagascar has suffered bubonic plague outbreaks almost every year since 1980 , often caused by rats fleeing forest fires .', 'The disease tends to make a comeback each hot rainy season , from September to April .', 'On average , between 300 and 600 infections are recorded every year among a population approaching 25 million people , according to a UN estimate .', 'But Tedros voiced alarm that \"\"\"\" plague in Madagascar behaved in a very , very different way this year . \"\"\"\"', 'Cases sprang up far earlier than usual and , instead of being confined to the countryside , the disease infiltrated towns .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNRWOyBjyZCf",
        "colab_type": "text"
      },
      "source": [
        "Flattening to merge easily as single dataframe column corresponding one-to-one with each token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns2aGb7VrSUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in np_list for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaCFhPUx1Fa",
        "colab_type": "text"
      },
      "source": [
        "The number of 0's and 1's equals the number of tokens in our original train+dev dataframe! Every token has been checked to be in an NP chunk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0KmbUuErmJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00a54c51-684f-4639-d239-dc187d125e60"
      },
      "source": [
        "len(flat_list)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p1jSNmHsAF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "isin_np_df = pd.DataFrame({'isin_np':flat_list})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA2XWHUvs2_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df = pd.merge(isin_np_df, train_df, left_index=True, right_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp9mRxxdttUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_df_1 = merged_df[['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label', 'positive', 'negative', 'arglex_any','isin_np','ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70xlQXMFtbgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "fe8fce36-ae61-4456-b784-c614255e396e"
      },
      "source": [
        "print(list(merged_df_1.columns))\n",
        "print(merged_df_1.head())"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label', 'positive', 'negative', 'arglex_any', 'isin_np', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']\n",
            "   document_id  sent_id  token_start  token_end       token label  positive  \\\n",
            "0  111111111    1        0            4          Next        O     0.000000   \n",
            "1  111111111    1        5            11         plague      O     0.071429   \n",
            "2  111111111    1        12           20         outbreak    O     0.000000   \n",
            "3  111111111    1        21           23         in          O     0.000000   \n",
            "4  111111111    1        24           34         Madagascar  O     0.000000   \n",
            "\n",
            "   negative  arglex_any  isin_np  ADJ  ADP  ADV  CCONJ  DET  INTJ  NOUN  NUM  \\\n",
            "0  0.031250  0           1.0      1    0    0    0      0    0     0     0     \n",
            "1  0.214286  0           1.0      0    0    0    0      0    0     1     0     \n",
            "2  0.125000  0           1.0      0    0    0    0      0    0     1     0     \n",
            "3  0.000000  0           0.0      0    1    0    0      0    0     0     0     \n",
            "4  0.000000  0           1.0      0    0    0    0      0    0     0     0     \n",
            "\n",
            "   PART  PRON  PROPN  PUNCT  SYM  VERB  X  \n",
            "0  0     0     0      0      0    0     0  \n",
            "1  0     0     0      0      0    0     0  \n",
            "2  0     0     0      0      0    0     0  \n",
            "3  0     0     0      0      0    0     0  \n",
            "4  0     0     1      0      0    0     0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4N4gvqxug1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = merged_df_1.to_csv(\"si-train+dev+dependency.tsv\", sep='\\t')\n",
        "from google.colab import files\n",
        "files.download(\"si-train+dev+dependency.tsv\") "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}