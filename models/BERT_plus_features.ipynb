{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_plus_features.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebJOhLaEkcMF",
        "colab_type": "text"
      },
      "source": [
        "Import, install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT5uU_XirQg9",
        "colab_type": "code",
        "outputId": "2c54b4e9-b7ee-4ccd-c500-556b391c5ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 33.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.40)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.40)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeZdp0Qyn-0A",
        "colab_type": "code",
        "outputId": "d266af0f-7210-43a5-c3e8-a09a571669a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import itertools\n",
        "\n",
        "# Creating the model\n",
        "from keras.layers import Bidirectional, CuDNNLSTM, Dense, Dropout, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Results analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case= False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 213450/213450 [00:00<00:00, 1130228.31B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvtbZCzakJrM",
        "colab_type": "text"
      },
      "source": [
        "# **Get data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtqnr63fn-TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-improved-sentiwordnet-arguingfull-pos.tsv?token=AFDEFD2TTBVOXQZ6HVMFGMC6DR6RM'\n",
        "train_df = pd.read_csv(train_url,sep='\\t', header=4, quoting = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa8ucB2-yhUB",
        "colab_type": "code",
        "outputId": "3e293806-4230-4c0f-fd2d-a9e3bc82dc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token_start</th>\n",
              "      <th>token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>label</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>arglex</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>ADP</th>\n",
              "      <th>ADV</th>\n",
              "      <th>CCONJ</th>\n",
              "      <th>DET</th>\n",
              "      <th>INTJ</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>NUM</th>\n",
              "      <th>PART</th>\n",
              "      <th>PRON</th>\n",
              "      <th>PROPN</th>\n",
              "      <th>PUNCT</th>\n",
              "      <th>SYM</th>\n",
              "      <th>VERB</th>\n",
              "      <th>X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Next</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>plague</td>\n",
              "      <td>O</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Madagascar</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_id  token_start  token_end  ... PUNCT SYM  VERB  X\n",
              "0    111111111        1            0          4  ...     0   0     0  0\n",
              "1    111111111        1            5         11  ...     0   0     0  0\n",
              "2    111111111        1           12         20  ...     0   0     0  0\n",
              "3    111111111        1           21         23  ...     0   0     0  0\n",
              "4    111111111        1           24         34  ...     0   0     0  0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN1Utko0y1iQ",
        "colab_type": "code",
        "outputId": "5866d558-c7d1-43ac-941a-57b18cc2c0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(401288, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4aztQjNkSXT",
        "colab_type": "text"
      },
      "source": [
        "# **Get sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO08FWIQ5A55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sents(train_df):\n",
        "  df_sents = train_df.groupby('sent_id')['token'].apply(list)\n",
        "  df_sents = df_sents.to_frame()\n",
        "  df_sents['sent_id'] = df_sents.index\n",
        "  df_sents[\"sentences\"]= df_sents[\"token\"].str.join(\" \")\n",
        "  return df_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLnjKVtI5QVm",
        "colab_type": "code",
        "outputId": "951313b8-b0d2-493b-b477-2899cf2c36d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "df_sents = get_sents(train_df)\n",
        "df_sents.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Next, plague, outbreak, in, Madagascar, could...</td>\n",
              "      <td>1</td>\n",
              "      <td>Next plague outbreak in Madagascar could be ' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Geneva, -, The, World, Health, Organisation, ...</td>\n",
              "      <td>2</td>\n",
              "      <td>Geneva - The World Health Organisation chief o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\", The, next, transmission, could, be, more, ...</td>\n",
              "      <td>3</td>\n",
              "      <td>\" The next transmission could be more pronounc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[An, outbreak, of, both, bubonic, plague, ,, w...</td>\n",
              "      <td>4</td>\n",
              "      <td>An outbreak of both bubonic plague , which is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[has, killed, more, than, 200, people, in, the...</td>\n",
              "      <td>5</td>\n",
              "      <td>has killed more than 200 people in the Indian ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     token  ...                                          sentences\n",
              "sent_id                                                     ...                                                   \n",
              "1        [Next, plague, outbreak, in, Madagascar, could...  ...  Next plague outbreak in Madagascar could be ' ...\n",
              "2        [Geneva, -, The, World, Health, Organisation, ...  ...  Geneva - The World Health Organisation chief o...\n",
              "3        [\", The, next, transmission, could, be, more, ...  ...  \" The next transmission could be more pronounc...\n",
              "4        [An, outbreak, of, both, bubonic, plague, ,, w...  ...  An outbreak of both bubonic plague , which is ...\n",
              "5        [has, killed, more, than, 200, people, in, the...  ...  has killed more than 200 people in the Indian ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6Lkl27-eW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sents_as_arrays(df_sents):\n",
        "  \"\"\"Get one list of tokens per sentence, corresponding to the tokens in that sentence.\"\"\"\n",
        "  token_lists = df_sents[\"token\"].tolist()  \n",
        "  return token_lists\n",
        "\n",
        "def normalize_sents(MAX_SEQ_LEN, token_lists):\n",
        "  \"\"\"Cap all token lists at max sequence length tokens and join them into sentence strings\"\"\"\n",
        "  merge_test_text_normalized = []\n",
        "  for sent in token_lists:\n",
        "    if len(sent) > MAX_SEQ_LEN:\n",
        "      merge_test_text_normalized.append(sent[:MAX_SEQ_LEN])\n",
        "    else:\n",
        "      merge_test_text_normalized.append(sent)\n",
        "\n",
        "  normalized_sent_list = []\n",
        "  for i in merge_test_text_normalized:\n",
        "    normalized_sent_list.append(\" \".join(str(j) for j in i))\n",
        "\n",
        "  return normalized_sent_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlsERLkB5av0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LEN = 35"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0YBwEI5IoP_",
        "colab_type": "code",
        "outputId": "3a0a1ff1-a80d-4b37-df2e-3ad162530c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "token_lists = get_sents_as_arrays(df_sents)\n",
        "normalized_sent_list = normalize_sents(MAX_SEQ_LEN, token_lists)\n",
        "\n",
        "print(token_lists[0:5])\n",
        "print(normalized_sent_list[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Next', 'plague', 'outbreak', 'in', 'Madagascar', 'could', 'be', \"'\", 'stronger', \"'\", ':', 'WHO'], ['Geneva', '-', 'The', 'World', 'Health', 'Organisation', 'chief', 'on', 'Wednesday', 'said', 'a', 'deadly', 'plague', 'epidemic', 'appeared', 'to', 'have', 'been', 'brought', 'under', 'control', 'in', 'Madagascar', ',', 'but', 'warned', 'the', 'next', 'outbreak', 'would', 'likely', 'be', 'stronger', '.'], ['\"', 'The', 'next', 'transmission', 'could', 'be', 'more', 'pronounced', 'or', 'stronger', ',', '\"', 'WHO', 'Director', '-', 'General', 'Tedros', 'Adhanom', 'Ghebreyesus', 'told', 'reporters', 'in', 'Geneva', ',', 'insisting', 'that', '\"', 'the', 'issue', 'is', 'serious', '.', '\"'], ['An', 'outbreak', 'of', 'both', 'bubonic', 'plague', ',', 'which', 'is', 'spread', 'by', 'infected', 'rats', 'via', 'flea', 'bites', ',', 'and', 'pneumonic', 'plague', ',', 'spread', 'person', 'to', 'person', ','], ['has', 'killed', 'more', 'than', '200', 'people', 'in', 'the', 'Indian', 'Ocean', 'island', 'nation', 'since', 'August', '.']]\n",
            "[\"Next plague outbreak in Madagascar could be ' stronger ' : WHO\", 'Geneva - The World Health Organisation chief on Wednesday said a deadly plague epidemic appeared to have been brought under control in Madagascar , but warned the next outbreak would likely be stronger .', '\" The next transmission could be more pronounced or stronger , \" WHO Director - General Tedros Adhanom Ghebreyesus told reporters in Geneva , insisting that \" the issue is serious . \"', 'An outbreak of both bubonic plague , which is spread by infected rats via flea bites , and pneumonic plague , spread person to person ,', 'has killed more than 200 people in the Indian Ocean island nation since August .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H0BwU2tkSz4",
        "colab_type": "text"
      },
      "source": [
        "#**Process sentences as needed for BERT**\n",
        "\n",
        "BERT requires:\n",
        "\n",
        "\n",
        "*   Tokenized sentences with beginning and end markers ([CLS] and [SEP])\n",
        "*   Tokens mapped to their integer ID's within BERT's vocabulary, padded to the max sequence length\n",
        "*   Attention masks of 1's for tokens and 0's for padding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMnSSkpwJ9_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_bert_special_tokens_and_tokenize(normalized_sent_list):\n",
        "  bert_tokenized_sent_list = []\n",
        "  bert_indexed_tokens_list = []\n",
        "  for sent in normalized_sent_list:\n",
        "    sent = \"[CLS] \" + sent + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(sent)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    bert_tokenized_sent_list.append(tokenized_text)\n",
        "    bert_indexed_tokens_list.append(indexed_tokens)\n",
        "\n",
        "  return bert_tokenized_sent_list, bert_indexed_tokens_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cspKVa-wLtpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_preprocessed_sents = add_bert_special_tokens_and_tokenize(normalized_sent_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcMjAwn3Zm37",
        "colab_type": "code",
        "outputId": "118ff117-8a86-4984-bef1-ef3319fffef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "bert_tokenized_sent_list = bert_preprocessed_sents[0]\n",
        "bert_indexed_tokens_list = bert_preprocessed_sents[1]\n",
        "\n",
        "print(bert_tokenized_sent_list[0])\n",
        "print(bert_indexed_tokens_list[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Next', 'plague', 'outbreak', 'in', 'Madagascar', 'could', 'be', \"'\", 'stronger', \"'\", ':', 'WHO', '[SEP]']\n",
            "[101, 5893, 13824, 8010, 1107, 12014, 1180, 1129, 112, 5992, 112, 131, 23750, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0snS0L1nS5-m",
        "colab_type": "text"
      },
      "source": [
        "Padding \n",
        "\n",
        "source: https://mccormickml.com/2019/07/22/BERT-fine-tuning/#32-sentences-to-ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ7loYKZS5aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_to_max_len(MAX_SEQ_LEN, bert_indexed_tokens_list):\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % MAX_SEQ_LEN)\n",
        "\n",
        "  bert_indexed_tokens_list = pad_sequences(bert_indexed_tokens_list, maxlen=MAX_SEQ_LEN, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\nDone.')\n",
        "  return bert_indexed_tokens_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiMBPCVmftYy",
        "colab_type": "code",
        "outputId": "b93dfa89-17af-45c9-f638-357de815e0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bert_indexed_tokens_list = pad_to_max_len(MAX_SEQ_LEN, bert_indexed_tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 35 values...\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrAxOeLrbiKV",
        "colab_type": "code",
        "outputId": "92bc0144-3096-4749-d354-d006ad98bad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "bert_indexed_tokens_list[0:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,  5893, 13824,  8010,  1107, 12014,  1180,  1129,   112,\n",
              "         5992,   112,   131, 23750,   102,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0],\n",
              "       [  101,  9571,   118,  1109,  1291,  3225, 14213,  2705,  1113,\n",
              "         9031,  1163,   170, 10310, 13824, 18162,  1691,  1106,  1138,\n",
              "         1151,  1814,  1223,  1654,  1107, 12014,   117,  1133,  6926,\n",
              "         1103,  1397,  8010,  1156,  2620,  1129,  5992,   119],\n",
              "       [  101,   107,  1109,  1397,  6580,  1180,  1129,  1167,  8481,\n",
              "         1137,  5992,   117,   107, 23750,  2524,   118,  1615,  6564,\n",
              "         5864, 24930,  3822,  4165,   144,  4638,  9730, 25014,  1361,\n",
              "         1500, 13509,  1107,  9571,   117, 25504,  1115,   107],\n",
              "       [  101,  1760,  8010,  1104,  1241,   171, 10354, 13207, 13824,\n",
              "          117,  1134,  1110,  2819,  1118, 10594, 13475,  2258, 22593,\n",
              "         4490, 17905,   117,  1105,   185,  1673,  1818, 13207, 13824,\n",
              "          117,  2819,  1825,  1106,  1825,   117,   102,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj06Z7gOd6uV",
        "colab_type": "text"
      },
      "source": [
        "Add attention masks to tell BERT what is a token and what is padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVkKBFo5d6De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_attention_masks(bert_indexed_tokens_list): \n",
        "  attention_masks = []\n",
        "  for sent in bert_indexed_tokens_list:\n",
        "      #bool True cast to int is 1\n",
        "      att_mask = [int(token_id > 0) for token_id in sent]\n",
        "      attention_masks.append(att_mask)\n",
        "  return attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8fbda5b4-aeee-49e3-d920-6234bbe8ba64",
        "id": "t4XYjmZqR3UD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "bert_indexed_tokens_list_first = bert_indexed_tokens_list[:len(bert_indexed_tokens_list)//2]\n",
        "bert_indexed_tokens_list_second = bert_indexed_tokens_list[len(bert_indexed_tokens_list)//2:]\n",
        "print(len(bert_indexed_tokens_list_first))\n",
        "print(len(bert_indexed_tokens_list_second))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10750\n",
            "10751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi2R6LCNeX-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attention_masks = add_attention_masks(bert_indexed_tokens_list)\n",
        "# print(attention_masks[0:4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_i0nkCkbAhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks_1 = add_attention_masks(bert_indexed_tokens_list_first)\n",
        "attention_masks_2 = add_attention_masks(bert_indexed_tokens_list_second)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQmEK9zTkSp8",
        "colab_type": "text"
      },
      "source": [
        "#**Section 4: Load BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCgrk3cUbNkf",
        "colab_type": "code",
        "outputId": "d22dbeca-42ad-4347-899a-d56562cb58b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor_1 = torch.tensor([bert_indexed_tokens_list_first])\n",
        "tokens_tensor_2 = torch.tensor([bert_indexed_tokens_list_second])\n",
        "segments_tensors_1 = torch.tensor([attention_masks_1])\n",
        "segments_tensors_2 = torch.tensor([attention_masks_2])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 404400730/404400730 [00:09<00:00, 43313603.54B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OU6NRgisrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Convert inputs to PyTorch tensors\n",
        "# tokens_tensor = torch.tensor([bert_indexed_tokens_list])\n",
        "# segments_tensors = torch.tensor([attention_masks])\n",
        "\n",
        "# # Load pre-trained model (weights)\n",
        "# model = BertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "# # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "# model.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaBVmzwok1Rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(tokens_tensor.size())\n",
        "# print(segments_tensors.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqiFDvrGngZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens_tensor = tokens_tensor.view(21501, MAX_SEQ_LEN)\n",
        "# segments_tensors = segments_tensors.view(21501, MAX_SEQ_LEN)\n",
        "# print(tokens_tensor.size())\n",
        "# print(segments_tensors.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RmRzfohbpdw",
        "colab_type": "code",
        "outputId": "5d41eea1-bb4d-4b55-8eff-d11409508a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "tokens_tensor_1 = tokens_tensor_1.view(10750, MAX_SEQ_LEN)\n",
        "segments_tensors_1 = segments_tensors_1.view(10750, MAX_SEQ_LEN)\n",
        "tokens_tensor_2 = tokens_tensor_2.view(10751, MAX_SEQ_LEN)\n",
        "segments_tensors_2 = segments_tensors_2.view(10751, MAX_SEQ_LEN)\n",
        "print(tokens_tensor_1.size())\n",
        "print(segments_tensors_1.size())\n",
        "print(tokens_tensor_2.size())\n",
        "print(segments_tensors_2.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10750, 35])\n",
            "torch.Size([10750, 35])\n",
            "torch.Size([10751, 35])\n",
            "torch.Size([10751, 35])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrLcz6XaSysg",
        "colab_type": "text"
      },
      "source": [
        "What if we simply ran the below cell twice with both of the things and then appended them? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT7wwpuRpiMf",
        "colab_type": "text"
      },
      "source": [
        "Add batching if ram overflows!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ze00uELnWcR",
        "colab_type": "code",
        "outputId": "97ddc480-d66d-4f50-fd76-fb25f5a1e88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "embed_batch_size = 500\n",
        "all_bert_embeddings_1 = []\n",
        "len_dataset = len(bert_indexed_tokens_list_first)\n",
        "for i in range(0, len_dataset, embed_batch_size):\n",
        "  print(\"Batch up until:\", i + embed_batch_size)\n",
        "  with torch.no_grad():\n",
        "    encoded_layers_1, _ = model(tokens_tensor_1[i:min(len_dataset, i + embed_batch_size)], segments_tensors_1[i:min(len_dataset, i + embed_batch_size)])\n",
        "    all_bert_embeddings_1.append(encoded_layers_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch up until: 500\n",
            "Batch up until: 1000\n",
            "Batch up until: 1500\n",
            "Batch up until: 2000\n",
            "Batch up until: 2500\n",
            "Batch up until: 3000\n",
            "Batch up until: 3500\n",
            "Batch up until: 4000\n",
            "Batch up until: 4500\n",
            "Batch up until: 5000\n",
            "Batch up until: 5500\n",
            "Batch up until: 6000\n",
            "Batch up until: 6500\n",
            "Batch up until: 7000\n",
            "Batch up until: 7500\n",
            "Batch up until: 8000\n",
            "Batch up until: 8500\n",
            "Batch up until: 9000\n",
            "Batch up until: 9500\n",
            "Batch up until: 10000\n",
            "Batch up until: 10500\n",
            "Batch up until: 11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_CWl5bbvzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed_batch_size = 500\n",
        "# all_bert_embeddings_2 = []\n",
        "# len_dataset = len(bert_indexed_tokens_list_second)\n",
        "# for i in range(0, len_dataset, embed_batch_size):\n",
        "#   print(\"Batch up until:\", i + embed_batch_size)\n",
        "#   with torch.no_grad():\n",
        "#     encoded_layers_2, _ = model(tokens_tensor_2[i:min(len_dataset, i + embed_batch_size)], segments_tensors_2[i:min(len_dataset, i + embed_batch_size)])\n",
        "#     all_bert_embeddings_2.append(encoded_layers_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J104DjnIdeNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed_batch_size = 1000\n",
        "# all_bert_embeddings = []\n",
        "# len_dataset = len(bert_indexed_tokens_list)\n",
        "# for i in range(0, len_dataset, embed_batch_size):\n",
        "#   print(\"Batch up until:\", i + embed_batch_size)\n",
        "#   with torch.no_grad():\n",
        "#     encoded_layers, _ = model(tokens_tensor[i:min(len_dataset, i + embed_batch_size)], segments_tensors[i:min(len_dataset, i + embed_batch_size)])\n",
        "#     all_bert_embeddings.append(encoded_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYT9QOkq3f3",
        "colab_type": "code",
        "outputId": "10ccbd18-91a1-4857-aea8-bb46a00a4909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print (\"Number of batches:\", len(all_bert_embeddings_1))\n",
        "layer_i = 0\n",
        "print (\"Number of layers:\", len(all_bert_embeddings_1[layer_i]))\n",
        "sentence_i = 0\n",
        "print (\"Number of sentences:\", len(all_bert_embeddings_1[layer_i][sentence_i]))\n",
        "token_i = 0\n",
        "print (\"Number of tokens in each sentence:\", len(all_bert_embeddings_1[layer_i][sentence_i][token_i]))\n",
        "embedding_i = 0\n",
        "print (\"Number of ints per token embedding:\", len(all_bert_embeddings_1[layer_i][sentence_i][token_i][embedding_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of batches: 22\n",
            "Number of layers: 12\n",
            "Number of sentences: 500\n",
            "Number of tokens in each sentence: 35\n",
            "Number of ints per token embedding: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Pjf6STkS6h",
        "colab_type": "text"
      },
      "source": [
        "Find several pooling strategies to turn into word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8mGwUzkSnkK",
        "colab_type": "code",
        "outputId": "a7a98a64-8c37-468a-9077-c6f9a8d539c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# `encoded_layers` is a Python list.\n",
        "print('     Type of : ', type(all_bert_embeddings_1))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', all_bert_embeddings_1[0][0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Type of :  <class 'list'>\n",
            "Tensor shape for each layer:  torch.Size([500, 35, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilf7V-K9nvNt",
        "colab_type": "code",
        "outputId": "633f9135-97bb-463a-91d6-c64dc68387a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "stacked_embeds = []\n",
        "for batch in all_bert_embeddings_1:\n",
        "  for sent in batch:\n",
        "    # Swap dimensions 0 and 1.\n",
        "    token_embeddings_2 = sent.permute(1,0,2)\n",
        "    print(token_embeddings_2.size())\n",
        "    stacked_embeds.append(token_embeddings_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 500, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n",
            "torch.Size([35, 250, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkGduVM3n7cd",
        "colab_type": "code",
        "outputId": "947e59d5-68f7-4909-e873-1e7c9a528fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings_1 = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings_1.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 250, 35, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7gtTpDGo0OE",
        "colab_type": "code",
        "outputId": "15803623-8193-401f-e0a0-2627d931d46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings_2 = token_embeddings_1.permute(1,2,0,3)\n",
        "\n",
        "token_embeddings_2.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([250, 35, 12, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFxiHxWcqGMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(token_embeddings_2, 'token_embeddings_2.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9WHWDsGqL09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('token_embeddings_2.pt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HPH7HrAVSQc",
        "colab_type": "code",
        "outputId": "128fa486-f139-4b3a-b483-dd00a7627527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [ x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for batch in token_embeddings_2:\n",
        "  print(len(batch))\n",
        "  for token in batch:\n",
        "\n",
        "      # `token` is a [12 x 768] tensor\n",
        "\n",
        "      # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "      \n",
        "      # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "Shape is: 8750 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqcNrtIYcqE",
        "colab_type": "code",
        "outputId": "8cb509bd-5784-478f-807e-8133bf827632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('hi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL3liDvNpXuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Stores the token vectors, with shape [22 x 3,072]\n",
        "# token_vecs_cat = []\n",
        "\n",
        "# # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# # For each token in the sentence...\n",
        "# #for batch in token_embeddings\n",
        "# #for whatever in batch\n",
        "# for token in token_embeddings:\n",
        "    \n",
        "#     # `token` is a [12 x 768] tensor\n",
        "\n",
        "#     # Concatenate the vectors (that is, append them together) from the last \n",
        "#     # four layers.\n",
        "#     # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "#     cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "#     # Use `cat_vec` to represent `token`.\n",
        "#     token_vecs_cat.append(cat_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-H9FzC_lqcS",
        "colab_type": "text"
      },
      "source": [
        "Make sure tokens align"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2LSbMyJkS-U",
        "colab_type": "text"
      },
      "source": [
        "Get features per token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxnDdYQbkTBf",
        "colab_type": "text"
      },
      "source": [
        "Append to word embeddings, dimension should end in ~800"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC3DY0_Sm-AA",
        "colab_type": "text"
      },
      "source": [
        "Get IO (not BIO) labels! Make this reproducible for devset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrsQJ6dJjfYG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HohOfVQZnMd7",
        "colab_type": "text"
      },
      "source": [
        "Pass through model, don't do test train split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSpPm4ARnSWg",
        "colab_type": "text"
      },
      "source": [
        "Do same thing all over again to devset"
      ]
    }
  ]
}