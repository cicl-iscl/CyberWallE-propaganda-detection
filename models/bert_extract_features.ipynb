{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_extract_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPjzZcHHZuE",
        "colab_type": "text"
      },
      "source": [
        "# Token-level BERT embeddings\n",
        "\n",
        "Partially adapted from https://github.com/huggingface/transformers/blob/3763f8944dc3fef8afb0c525a2ced8a04889c14f/examples/extract_features.py\n",
        "(Apache License 2.0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQM4ABPLy5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRZKVwilvnSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install seqeval    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHJxYR06vgrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import urllib\n",
        "import pandas as pd\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZnTBzZvymH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 85\n",
        "BATCH_SIZE = 32\n",
        "LAYERS = [-1]\n",
        "TRAIN_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-improved-sentiwordnet-arguingfullindiv-pos.tsv?token=AD7GEDPOUJFOQS3HTDRWMOS6KZP62'\n",
        "DEV_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-improved-sentiwordnet-arguingfullindiv-pos.tsv?token=AD7GEDNCXBQCYYC5ZKLNIWC6KZP6Y'\n",
        "TEST_URL = ''\n",
        "# OUT_PREFIX = '/content/gdrive/My Drive/colab_projects/data/'\n",
        "OUT_PREFIX = ''\n",
        "\n",
        "# Toggle this!\n",
        "MODE = 'train'\n",
        "# MODE = 'dev'\n",
        "# MODE = 'test'\n",
        "\n",
        "if MODE == 'train':\n",
        "    IN_URL = TRAIN_URL\n",
        "elif MODE == 'dev':\n",
        "    IN_URL = DEV_URL\n",
        "elif MODE == 'test':\n",
        "    IN_URL = TEST_URL\n",
        "\n",
        "OUT_FILE = OUT_PREFIX + MODE + '_bert.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43x0CqLkyprJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0) \n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw53eIej-9wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_comments(filename, url=True):\n",
        "    if url:\n",
        "        comments = []\n",
        "        with urllib.request.urlopen(filename) as f:\n",
        "            for line in f:\n",
        "                if line.startswith(b'#'):\n",
        "                    comments.append(line.decode(\"utf-8\"))\n",
        "                else:\n",
        "                    break\n",
        "        return comments\n",
        "    with open(filename, 'r', encoding='utf8') as f:\n",
        "        commentiter = takewhile(lambda s: s.startswith('#'), f)\n",
        "        comments = list(commentiter)\n",
        "    return comments\n",
        "\n",
        "comments = get_comments(IN_URL)\n",
        "full_df = pd.read_csv(IN_URL, sep='\\t', skiprows=len(comments), quoting=3)\n",
        "sent_df = full_df.groupby('sent_id')['token'].apply(list).to_frame()\n",
        "sentences = sent_df['token'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr12SCKSauVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputFeatures(object):\n",
        "\n",
        "    def __init__(self, tokens, sent_idx, input_ids, input_mask):\n",
        "        self.tokens = tokens\n",
        "        self.sent_idx = sent_idx\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "\n",
        "\n",
        "def convert_sentences_to_features(sentences, seq_length, tokenizer):\n",
        "    features = []\n",
        "    for (idx, tok_list) in enumerate(sentences, start=1):\n",
        "        tok_list = [str(tok).lower() for tok in tok_list]\n",
        "        sentence = ' '.join(tok_list)\n",
        "        tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "        # +2 = [CLS] and [SEP]\n",
        "        if len(tokens) + 2 > seq_length:\n",
        "            print('Sentence will be truncated', len(tokens), idx)\n",
        "            print(sentence)\n",
        "            print(tokens)\n",
        "            tokens = tokens[0:(seq_length - 2)]\n",
        "\n",
        "        tokens.insert(0, '[CLS]')\n",
        "        tokens.append('[SEP]')\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        while len(input_ids) < seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "\n",
        "        assert len(input_ids) == seq_length\n",
        "        assert len(input_mask) == seq_length\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                tokens=tokens,\n",
        "                sent_idx=idx,\n",
        "                input_ids=input_ids,\n",
        "                input_mask=input_mask))\n",
        "    return idx, features\n",
        "\n",
        "n_sents, features = convert_sentences_to_features(sentences, MAX_LEN + 2, tokenizer)\n",
        "\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_indices = torch.arange(n_sents, dtype=torch.long)\n",
        "\n",
        "data = TensorDataset(all_input_ids, all_input_mask, all_indices)\n",
        "sampler = SequentialSampler(data)\n",
        "dataloader = DataLoader(data, sampler=sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvGg0uZrYm-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The loop nesting is really inopportune, but it is (partially?) caused by the batching\n",
        "\n",
        "model.eval()\n",
        "with open(OUT_FILE, 'w', encoding='utf-8') as f:\n",
        "    for input_ids, input_mask, index_batch in dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "\n",
        "        all_encoder_layers, _ = model(input_ids, token_type_ids=None, \n",
        "                                      attention_mask=input_mask)\n",
        "        # all_encoder_layers = all_encoder_layers\n",
        "\n",
        "        for b, idx in enumerate(index_batch):\n",
        "            feature = features[idx.item()]\n",
        "            sent_idx = feature.sent_idx\n",
        "            for (tok_idx, token) in enumerate(feature.tokens):\n",
        "                if token in ['[CLS]', '[SEP]']:\n",
        "                    continue\n",
        "                for layer in LAYERS:\n",
        "                    layer_output = all_encoder_layers[int(layer)].detach().cpu().numpy()\n",
        "                    layer_output = layer_output[b]\n",
        "                    values = [round(x.item(), 9) for x in layer_output[tok_idx]]\n",
        "                    out = str(sent_idx) + '\\t' + str(layer) + '\\t' + token + '\\t' + str(values)\n",
        "                    f.write(out + '\\n')\n",
        "                    if (sent_idx % 1000 == 0 and tok_idx == 1):\n",
        "                        print(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5v8wlG3vBq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !head '/content/gdrive/My Drive/colab_projects/data/train_bert.tsv'\n",
        "!mv -v train_bert.tsv '/content/gdrive/My Drive/colab_projects/data/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}