{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline-bilstm",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VubK6qZQUmeM",
        "colab_type": "text"
      },
      "source": [
        "# Challenges in NLP, WS19/20\n",
        "\n",
        "Blaschke Verena, ISCL MA<br/>\n",
        "Korniyenko Maxim, ISCL MA<br/>\n",
        "Tureski Sam, ML MA<br/>\n",
        "\n",
        "-----\n",
        "## Baseline model for Span Identification task\n",
        "-----\n",
        "\n",
        "The working process looks like the following:\n",
        "- Data preparation.\n",
        "- Creating the model.\n",
        "- Training the model.\n",
        "- Testing the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSkNNNrI9ZxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "01078598-5871-45bd-d162-d32556376c85"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from enum import Enum\n",
        "\n",
        "# Creating the model\n",
        "from keras.layers import Bidirectional, CuDNNLSTM, Dense, Dropout, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Results analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlVCNsD2-rfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing tools for oversampling\n",
        "# !pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e7X9fAvBftx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputType(Enum):\n",
        "    BASELINE = 1\n",
        "    IMPROVED = 2\n",
        "    BASELINE_TWENTY = 3\n",
        "    BASELINE_FOURTY = 4\n",
        "    BASELINE_FIFTY = 5\n",
        "    IMPROVED_SENTIMENT = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gmmsfrBXNW",
        "colab_type": "text"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tWOkKZNBbxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_type = InputType.BASELINE\n",
        "input_type = InputType.IMPROVED_SENTIMENT\n",
        "add_sentiment_features = True\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "batch_size = 128\n",
        "\n",
        "# epochs = 10\n",
        "epochs = 15\n",
        "\n",
        "N_CLASSES = 2\n",
        "# N_CLASSES = 3\n",
        "# class_weighting = False\n",
        "class_weighting = True\n",
        "o_weight = 1.0\n",
        "i_weight = 6.5\n",
        "b_weight = 6.5\n",
        "\n",
        "test_split = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttjmy-nhWB4r",
        "colab_type": "text"
      },
      "source": [
        "#1. Data preparation\n",
        "\n",
        "Deciding on the data preprocessing type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgRlLi2IAb3U",
        "colab_type": "text"
      },
      "source": [
        "Reading the data from the file and storing it in a data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORZhvz69htt",
        "colab_type": "code",
        "outputId": "24a3091f-943c-43bd-a304-ee24431eef93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "if input_type == InputType.IMPROVED:\n",
        "  train_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-bio-improved.tsv?token=AD7GEDJSZEXG4DJTXIDCSY2542WA4'\n",
        "elif input_type == InputType.BASELINE:\n",
        "  train_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-bio-baseline.tsv?token=AF75TYYBV4BIFHV3R5VNB2C537DZO'\n",
        "elif input_type == InputType.BASELINE_FIFTY:\n",
        "  train_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-bio-baseline-50.tsv?token=AD7GEDL2V5JNNRXKNTPVGAC54WIEQ'\n",
        "elif input_type == InputType.BASELINE_TWENTY:\n",
        "  # Uploaded this as a temp file to this colab project\n",
        "  train_url = '/content/train-data-bio-baseline-20.tsv'\n",
        "elif input_type == InputType.BASELINE_FOURTY:\n",
        "  # Uploaded this as a temp file to this colab project\n",
        "  train_url = '/content/train-data-bio-baseline-40.tsv'\n",
        "elif input_type == InputType.IMPROVED_SENTIMENT:\n",
        "  # Uploaded this as a temp file to this colab project\n",
        "  train_url = '/content/train-data-bio-improved-sentiment.tsv'\n",
        "\n",
        "names = [\"document_id\", \"sent_number\",\"idx_token_beginning\", \"idx_token_end\", \"token\", \"bio_label\"]\n",
        "if add_sentiment_features:\n",
        "  names.append(\"sentiment\")\n",
        "\n",
        "train_df = pd.read_csv(train_url, sep='\\t',names=names, quoting = 3)\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_number</th>\n",
              "      <th>idx_token_beginning</th>\n",
              "      <th>idx_token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>bio_label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Next</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>plague</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Madagascar</td>\n",
              "      <td>O</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_number  ...  bio_label  sentiment\n",
              "0    111111111            1  ...          O        0.0\n",
              "1    111111111            1  ...          O        0.0\n",
              "2    111111111            1  ...          O        0.0\n",
              "3    111111111            1  ...          O        0.0\n",
              "4    111111111            1  ...          O        0.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHqbQCKKFjHo",
        "colab_type": "text"
      },
      "source": [
        "Getting the data frame with sentences and saving tokens to the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PLC6gBkOtC7",
        "colab_type": "code",
        "outputId": "a147f86a-f2b8-46d7-f751-2bbfd04d4f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(train_df[\"bio_label\"].value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O    350354\n",
            "I     45542\n",
            "B      5392\n",
            "Name: bio_label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTMwJaN0Essg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence_list(input_df):\n",
        "  df_sents = input_df.groupby('sent_number')['token'].apply(list)\n",
        "  df_sents = df_sents.to_frame()\n",
        "  df_sents['sent_number'] = df_sents.index\n",
        "  df_sents[\"sentences\"]= df_sents[\"token\"].str.join(\" \")\n",
        "  sentence_list = df_sents[\"token\"].to_list()\n",
        "  return sentence_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj4lhGpfzX7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentence_list = get_sentence_list(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4akrSXlF6Nk",
        "colab_type": "text"
      },
      "source": [
        "Getting the data frame with labels and them to the list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRor6_kiFvc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cols(input_df, col='bio_label'):\n",
        "  df_labels = input_df.groupby('sent_number')[col].apply(list)\n",
        "  df_labels = df_labels.to_frame()\n",
        "  return df_labels[col].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pml6EzXRGiV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bio_sent_list = get_cols(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6HXbK-dwQEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if add_sentiment_features:\n",
        "  train_sentiment = get_cols(train_df, 'sentiment')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFczOPG1O0go",
        "colab_type": "text"
      },
      "source": [
        "## Encoding data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1W2oPTMG-n2",
        "colab_type": "code",
        "outputId": "35c624d2-6b4e-4b83-ac66-6942e8ac0cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if input_type == InputType.BASELINE_FIFTY:\n",
        "  MAX_SEQUENCE_LENGTH = 50\n",
        "elif input_type == InputType.BASELINE_TWENTY:\n",
        "  MAX_SEQUENCE_LENGTH = 20\n",
        "elif input_type == InputType.BASELINE_FOURTY:\n",
        "  MAX_SEQUENCE_LENGTH = 40\n",
        "else:\n",
        "  MAX_SEQUENCE_LENGTH = 35\n",
        "\n",
        "MAX_SEQUENCE_LENGTH"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HxXV8BHMuA",
        "colab_type": "text"
      },
      "source": [
        "#### Encoding features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCS3v6NgWkvO",
        "colab_type": "text"
      },
      "source": [
        "Reading the glove embeddings from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61OlM1uZHtMr",
        "colab_type": "code",
        "outputId": "8e9960b3-f8be-48ca-fabb-e3b6e7838200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ab1jvz0H6hV",
        "colab_type": "code",
        "outputId": "5c475b39-63b3-4cb1-cc89-9151139cb1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "file_path = 'gdrive/My Drive/colab_projects/data/glove.6B.100d.txt'\n",
        "f = open(file_path)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOIFqkxbHJfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_X(sentence_list, \n",
        "          max_sequence_length,\n",
        "          embedding_dim,\n",
        "          n_features,\n",
        "          sentiment_features):\n",
        "  # first create a matrix of zeros, this is our embedding matrix\n",
        "  embedding_matrix = np.zeros([len(sentence_list),\n",
        "                               max_sequence_length,\n",
        "                               embedding_dim + n_features])\n",
        "  print(embedding_matrix.shape)\n",
        "  # for each word in out tokenizer lets try to find that work in our w2v model\n",
        "  for i, sentence in enumerate(sentence_list):\n",
        "    for j, word in enumerate(sentence_list[i]):\n",
        "      if j > max_sequence_length:\n",
        "          #Split these longer sentences later\n",
        "          continue\n",
        "      embedding_vector = embeddings_index.get(word, np.random.randn(embedding_dim))\n",
        "      # if embedding_vector is not None:\n",
        "      #     # we found the word - add that words vector to the matrix\n",
        "      #     embedding_matrix[i] = embedding_vector\n",
        "      # else:\n",
        "      #     # doesn't exist, assign a random vector\n",
        "      #     embedding_matrix[i] = np.random.randn(embedding_dim)\n",
        "      if sentiment_features:\n",
        "        embedding_matrix[i][j][:embedding_dim] = embedding_vector\n",
        "        embedding_matrix[i][j][-n_features] = sentiment_features[i][j]\n",
        "      else:\n",
        "        embedding_matrix[i][j] = embedding_vector\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPJx2gI0f5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a07d5b97-0bc8-4f4b-e040-1987ba0d2b7a"
      },
      "source": [
        "n_features = 0\n",
        "if add_sentiment_features:\n",
        "  sentiment_features = train_sentiment\n",
        "  n_features = 1\n",
        "else:\n",
        "  sentiment_features = None\n",
        "\n",
        "train_features = get_X(sentence_list=train_sentence_list,\n",
        "                       max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                       embedding_dim=EMBEDDING_DIM,\n",
        "                       n_features=n_features,\n",
        "                       sentiment_features=sentiment_features)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21501, 35, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nb1HZ4VGkDI",
        "colab_type": "text"
      },
      "source": [
        "#### Encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxuy8104Xpbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if N_CLASSES == 3:\n",
        "  label2idx = {\"O\": [1, 0, 0], \"B\": [0, 0, 1], \"I\": [0, 1, 0]}\n",
        "elif N_CLASSES == 2:\n",
        "  label2idx = {\"O\": [1, 0], \"B\": [0, 1], \"I\": [0, 1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6N07KeGoZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_y(sentence_list, \n",
        "          bio_sent_list,\n",
        "          label_dict, \n",
        "          max_sequence_length, \n",
        "          n_classes):\n",
        "  # first create a matrix of zeros, this is our embedding matrix\n",
        "  if n_classes == 1:\n",
        "    labels = np.zeros([len(sentence_list), max_sequence_length])\n",
        "  else:\n",
        "    labels = np.zeros([len(sentence_list), max_sequence_length, n_classes])\n",
        "  # for each word in out tokenizer lets try to find that work in our w2v model\n",
        "  for i, sentence in enumerate(sentence_list):\n",
        "    for j, word in enumerate(bio_sent_list[i]):\n",
        "      if j < max_sequence_length:\n",
        "        labels[i][j] = label_dict.get(word)\n",
        "      else:\n",
        "        break\n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5gi1Fjc1bP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = get_y(sentence_list=train_sentence_list,\n",
        "          bio_sent_list=train_bio_sent_list,\n",
        "          label_dict=label2idx,\n",
        "          max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "          n_classes=N_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR41hLh6FlZq",
        "colab_type": "code",
        "outputId": "92fba68f-f772-459b-e160-c0f70713cbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "if class_weighting:\n",
        "  label2weight = {'O': o_weight, 'I': i_weight, 'B': b_weight}\n",
        "  sample_weight = get_y(sentence_list=train_sentence_list,\n",
        "                        bio_sent_list=train_bio_sent_list,\n",
        "                        label_dict=label2weight,\n",
        "                        max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                        n_classes=1)\n",
        "  print(sample_weight[2])\n",
        "else:\n",
        "  sample_weight = None"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.  6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 1.  1.  1.  1.  1.  1.  1.  1.\n",
            " 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hfh7R2LVt17",
        "colab_type": "text"
      },
      "source": [
        "BONUS: Some attempts of applying oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtsnOWMA_ycN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# smote = SMOTE(ratio='minority')\n",
        "# y_train=y_train.astype('int')\n",
        "# print(y_train[0])\n",
        "# rows = y_train.shape[0]\n",
        "# y_train = y_train.reshape(-1, n_classes).argmax(axis=1).flatten()\n",
        "# print(y_train.shape)\n",
        "# X_train = X_train.reshape(rows, MAX_SEQUENCE_LENGTH, 100).reshape(-1, 100)\n",
        "# print(X_train.shape)\n",
        "# X_sm, y_sm = smote.fit_sample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQntrhwhW0Lo",
        "colab_type": "text"
      },
      "source": [
        "# 2. Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuzEvEcGI1xd",
        "colab_type": "code",
        "outputId": "4951219b-3df1-47cf-9031-9ab61225fd1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True), input_shape=(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM + n_features)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(TimeDistributed(Dense(N_CLASSES, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy'],\n",
        "              sample_weight_mode='temporal')\n",
        "print(model.summary())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_2 (Bidirection (None, 35, 1024)          2519040   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 35, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 35, 2)             2050      \n",
            "=================================================================\n",
            "Total params: 2,521,090\n",
            "Trainable params: 2,521,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-1dXcmbXCUc",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR09KbvE9V4l",
        "colab_type": "text"
      },
      "source": [
        "#### Training using all of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQH38939TCJ",
        "colab_type": "code",
        "outputId": "98a1bdca-e33b-4d44-cfcf-4d146fbc02ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "history = model.fit(train_features, y, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.1, sample_weight=sample_weight)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 19350 samples, validate on 2151 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "19350/19350 [==============================] - 13s 673us/step - loss: 1.0726 - categorical_accuracy: 0.6878 - val_loss: 1.3092 - val_categorical_accuracy: 0.7697\n",
            "Epoch 2/15\n",
            "19350/19350 [==============================] - 4s 229us/step - loss: 1.0268 - categorical_accuracy: 0.7279 - val_loss: 1.2385 - val_categorical_accuracy: 0.6410\n",
            "Epoch 3/15\n",
            "19350/19350 [==============================] - 4s 231us/step - loss: 1.0117 - categorical_accuracy: 0.7023 - val_loss: 1.3267 - val_categorical_accuracy: 0.7938\n",
            "Epoch 4/15\n",
            "19350/19350 [==============================] - 4s 230us/step - loss: 0.9903 - categorical_accuracy: 0.6931 - val_loss: 1.2365 - val_categorical_accuracy: 0.6226\n",
            "Epoch 5/15\n",
            "19350/19350 [==============================] - 4s 227us/step - loss: 0.9516 - categorical_accuracy: 0.6693 - val_loss: 1.2600 - val_categorical_accuracy: 0.4909\n",
            "Epoch 6/15\n",
            "19350/19350 [==============================] - 4s 225us/step - loss: 0.9037 - categorical_accuracy: 0.6483 - val_loss: 1.3237 - val_categorical_accuracy: 0.5595\n",
            "Epoch 7/15\n",
            "19350/19350 [==============================] - 4s 227us/step - loss: 0.8221 - categorical_accuracy: 0.7032 - val_loss: 1.4197 - val_categorical_accuracy: 0.6152\n",
            "Epoch 8/15\n",
            "19350/19350 [==============================] - 4s 226us/step - loss: 0.7105 - categorical_accuracy: 0.7129 - val_loss: 1.4837 - val_categorical_accuracy: 0.5169\n",
            "Epoch 9/15\n",
            "19350/19350 [==============================] - 4s 225us/step - loss: 0.5915 - categorical_accuracy: 0.7457 - val_loss: 2.7172 - val_categorical_accuracy: 0.8639\n",
            "Epoch 10/15\n",
            "19350/19350 [==============================] - 4s 226us/step - loss: 0.4808 - categorical_accuracy: 0.8033 - val_loss: 2.4058 - val_categorical_accuracy: 0.6567\n",
            "Epoch 11/15\n",
            "19350/19350 [==============================] - 4s 224us/step - loss: 0.3900 - categorical_accuracy: 0.8007 - val_loss: 2.9654 - val_categorical_accuracy: 0.8241\n",
            "Epoch 12/15\n",
            "19350/19350 [==============================] - 4s 229us/step - loss: 0.3112 - categorical_accuracy: 0.8154 - val_loss: 3.6795 - val_categorical_accuracy: 0.6696\n",
            "Epoch 13/15\n",
            "19350/19350 [==============================] - 4s 226us/step - loss: 0.2476 - categorical_accuracy: 0.8485 - val_loss: 4.4846 - val_categorical_accuracy: 0.8064\n",
            "Epoch 14/15\n",
            "19350/19350 [==============================] - 4s 224us/step - loss: 0.2115 - categorical_accuracy: 0.8612 - val_loss: 4.4419 - val_categorical_accuracy: 0.7686\n",
            "Epoch 15/15\n",
            "19350/19350 [==============================] - 4s 227us/step - loss: 0.1777 - categorical_accuracy: 0.8707 - val_loss: 5.0263 - val_categorical_accuracy: 0.7692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-mWfrBz9VYe",
        "colab_type": "text"
      },
      "source": [
        "#### Training using only some part of the data. For testing the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMc4OyuIgvc",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJm_cXYpI_Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if test_split:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(train_features, y, test_size=0.1)\n",
        "  history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size, verbose=1, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cav1kjGKJlF5",
        "colab_type": "text"
      },
      "source": [
        "# 4. Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwPw0MN_Jnn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if test_split:\n",
        "  y_hat = model.predict(X_test)\n",
        "  y_hat_flat = y_hat.reshape(-1, N_CLASSES).argmax(axis=1)\n",
        "  y_test_flat = y_test.reshape(-1, N_CLASSES).argmax(axis=1)\n",
        "  print(f1_score(y_hat_flat, y_test_flat, average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeVF7DgmXP2U",
        "colab_type": "text"
      },
      "source": [
        "Making the true and predicted labels flat for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrZ07ubESnL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if test_split:\n",
        "  target_names = [\"O\", \"B\", \"I\"]\n",
        "  print(classification_report(y_test_flat, y_hat_flat, target_names=target_names))\n",
        "  print(confusion_matrix(y_true=y_test_flat, y_pred=y_hat_flat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLY5LLDu-aGd",
        "colab_type": "text"
      },
      "source": [
        "# 5. Getting predictions for development data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTcLhFOVKQrt",
        "colab_type": "text"
      },
      "source": [
        "Reading the development data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5nFG4sf-diO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if input_type == InputType.IMPROVED:\n",
        "  dev_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-improved.tsv?token=AD7GEDLLJXGKMJV76VSXIKC542WAY'\n",
        "elif input_type == InputType.BASELINE:\n",
        "  dev_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-baseline.tsv?token=AF75TY24Z3BQ7Q3XIJ4A4TC54BBQI'\n",
        "elif input_type == InputType.BASELINE_FIFTY:\n",
        "  dev_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-baseline-50.tsv?token=AD7GEDMOORVAKHCVCU2N2EK54WIN2'\n",
        "elif input_type == InputType.BASELINE_TWENTY:\n",
        "  dev_url = '/content/dev-baseline-20.tsv'\n",
        "elif input_type == InputType.BASELINE_FOURTY:\n",
        "  dev_url = '/content/dev-baseline-40.tsv'\n",
        "elif input_type == InputType.IMPROVED_SENTIMENT:\n",
        "  dev_url = '/content/dev-improved-sentiment.tsv'\n",
        "\n",
        "names = [\"document_id\", \"sent_number\",\"idx_token_beginning\", \"idx_token_end\", \"token\"]\n",
        "if add_sentiment_features:\n",
        "  names.append(\"sentiment\")\n",
        "dev_df = pd.read_csv(dev_url, sep='\\t',names=names, quoting = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r89uYLBWKWpE",
        "colab_type": "text"
      },
      "source": [
        "Getting the number of training instances (rows) in the data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw-3mLDpFYAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_rows_dev = dev_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51ORuD09KkR9",
        "colab_type": "text"
      },
      "source": [
        "Preparing the dev data and making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9tOrJ1D-u6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_sentence_list = get_sentence_list(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjHz4_MZ4zzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b85ecf5-acf3-4b1e-b99a-57b487a7872c"
      },
      "source": [
        "if add_sentiment_features:\n",
        "  dev_sentiment = get_cols(dev_df, 'sentiment')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuiVsr7S-26t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "465af441-6033-411b-a931-38bec851f579"
      },
      "source": [
        "dev_features = get_X(sentence_list=dev_sentence_list,\n",
        "                     max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                     embedding_dim=EMBEDDING_DIM,\n",
        "                     n_features=n_features,\n",
        "                     sentiment_features=dev_sentiment)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3830, 35, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxSwb0CM_Gnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model.predict(dev_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaJ4lsXhK8SV",
        "colab_type": "text"
      },
      "source": [
        "From one-hot encoding to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLVudMQZBm_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = y_hat.reshape(-1, N_CLASSES).argmax(axis=1).reshape(len(dev_sentence_list), MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtwvGRVyLFSP",
        "colab_type": "text"
      },
      "source": [
        "Mapping the predictions to the corresponding indeces in the dev data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiKKHORD_MtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_vector(sentence_list,\n",
        "                      predicted_labels,\n",
        "                      max_sequence_length,\n",
        "                      n_rows):\n",
        "\n",
        "  labels_vector = []\n",
        "\n",
        "  for i, _ in enumerate(sentence_list):\n",
        "    for j, _ in enumerate(sentence_list[i]):      \n",
        "      if predicted_labels[i][j] == 0:\n",
        "        label = \"O\"\n",
        "      elif predicted_labels[i][j] == 1:\n",
        "        label = \"I\"\n",
        "      else:\n",
        "        label = \"B\"\n",
        "      labels_vector.append(label)\n",
        "  return labels_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXk0goGJIN-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels_column = get_labels_vector(dev_sentence_list, \n",
        "                                            y_hat, \n",
        "                                            MAX_SEQUENCE_LENGTH,\n",
        "                                            n_rows_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxkp3Uu6LdcT",
        "colab_type": "text"
      },
      "source": [
        "Concatenation of the original dev data frame and the prediction vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1bCqoG2I-lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df = pd.concat([dev_df, pd.DataFrame(predicted_labels_column, columns=[\"bio_label\"])], axis=1, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xEvfqvyLlxk",
        "colab_type": "text"
      },
      "source": [
        "Overview of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReEg19naJJBd",
        "colab_type": "code",
        "outputId": "4b0b18d2-56db-44de-bd79-284d02410062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "result_df.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_number</th>\n",
              "      <th>idx_token_beginning</th>\n",
              "      <th>idx_token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>bio_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Police</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>had</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>previously</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>gone</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>to</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_number  ...  sentiment  bio_label\n",
              "0    730081389            1  ...        0.0          O\n",
              "1    730081389            1  ...        0.0          O\n",
              "2    730081389            1  ...        0.0          O\n",
              "3    730081389            1  ...        0.0          O\n",
              "4    730081389            1  ...        0.0          O\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ETlCuf3Jj29",
        "colab_type": "code",
        "outputId": "c1bb913d-9d6a-400d-e57b-228350b6d7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "result_df[\"bio_label\"].value_counts()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O    59211\n",
              "I     7962\n",
              "Name: bio_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzHxnLwkMytk",
        "colab_type": "text"
      },
      "source": [
        "Saving data frame to a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9fMlY7BMyWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df.to_csv(path_or_buf=\"dev_predictions_sentiment_bio.tsv\",\n",
        "                 sep=\"\\t\",\n",
        "                 header=False,\n",
        "                 index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}