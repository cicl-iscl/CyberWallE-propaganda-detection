{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline-bilstm",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VubK6qZQUmeM",
        "colab_type": "text"
      },
      "source": [
        "# Challenges in NLP, WS19/20\n",
        "\n",
        "Blaschke Verena, ISCL MA<br/>\n",
        "Korniyenko Maxim, ISCL MA<br/>\n",
        "Tureski Sam, ML MA<br/>\n",
        "\n",
        "-----\n",
        "## Baseline model for Span Identification task\n",
        "-----\n",
        "\n",
        "The working process looks like the following:\n",
        "- Data preparation.\n",
        "- Creating the model.\n",
        "- Training the model.\n",
        "- Testing the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSkNNNrI9ZxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from enum import Enum\n",
        "from itertools import takewhile\n",
        "import urllib.request\n",
        "\n",
        "# Creating the model\n",
        "from keras.layers import Bidirectional, CuDNNLSTM, Dense, Dropout, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Results analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlVCNsD2-rfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing tools for oversampling\n",
        "# !pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gmmsfrBXNW",
        "colab_type": "text"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tWOkKZNBbxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 35\n",
        "EMBEDDING_DIM = 100\n",
        "batch_size = 128\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "N_CLASSES = 2\n",
        "# N_CLASSES = 3\n",
        "class_weighting = True\n",
        "o_weight = 1.0\n",
        "i_weight = 6.5\n",
        "b_weight = 6.5\n",
        "\n",
        "test_split = False\n",
        "\n",
        "# train_url = '/content/train-data-improved-sentiwordnet-arguingfull.tsv'\n",
        "train_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-data-improved-sentiwordnet-arguingfull.tsv?token=AD7GEDO4X6BQYQGURMKJB7C57DXFK'\n",
        "# dev_url = '/content/dev-improved-sentiwordnet-arguingfull.tsv'\n",
        "dev_url = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-improved-sentiwordnet-arguingfull.tsv?token=AD7GEDLZIF6CIEOANPAMRVC57DXFQ'\n",
        "\n",
        "outfile = 'dev_predictions_bio.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttjmy-nhWB4r",
        "colab_type": "text"
      },
      "source": [
        "#1. Data preparation\n",
        "\n",
        "Deciding on the data preprocessing type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgRlLi2IAb3U",
        "colab_type": "text"
      },
      "source": [
        "Reading the data from the file and storing it in a data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9px5zsuDQt5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Version for files that are not specified via a URL:\n",
        "# def get_comments(filename):\n",
        "#   with open(filename, 'r', encoding='utf8') as f:\n",
        "#     commentiter = takewhile(lambda s: s.startswith('#'), f)\n",
        "#     comments = list(commentiter)\n",
        "#   return comments\n",
        "\n",
        "def get_comments(filename):\n",
        "  comments = []\n",
        "  with urllib.request.urlopen(filename) as f:\n",
        "    for line in f:\n",
        "      if line.startswith(b'#'):\n",
        "        comments.append(line)\n",
        "      else:\n",
        "        break\n",
        "  return comments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORZhvz69htt",
        "colab_type": "code",
        "outputId": "c1e7abe9-5e90-4e56-c325-f00ab6f318a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# We're getting the comments this way so we can:\n",
        "# - add them to the output\n",
        "# - parse lines that contain '#' as the token\n",
        "train_comments = get_comments(train_url)\n",
        "dev_comments = get_comments(dev_url)\n",
        "assert train_comments == dev_comments\n",
        "train_df = pd.read_csv(train_url, sep='\\t', skiprows=len(train_comments), quoting=3)\n",
        "dev_df = pd.read_csv(dev_url, sep='\\t', skiprows=len(dev_comments), quoting=3)\n",
        "\n",
        "std_cols = ['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label']\n",
        "feature_cols = []\n",
        "for col in train_df.columns:\n",
        "  if col not in std_cols:\n",
        "    feature_cols.append(col)\n",
        "\n",
        "print('features:', feature_cols)\n",
        "print(train_df[\"label\"].value_counts())\n",
        "train_df.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features: ['positive', 'negative', 'arglex']\n",
            "O    350354\n",
            "I     45542\n",
            "B      5392\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token_start</th>\n",
              "      <th>token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>label</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>arglex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Next</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>plague</td>\n",
              "      <td>O</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111111111</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Madagascar</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_id  token_start  ...  positive  negative arglex\n",
              "0    111111111        1            0  ...  0.000000  0.031250      0\n",
              "1    111111111        1            5  ...  0.071429  0.214286      0\n",
              "2    111111111        1           12  ...  0.000000  0.125000      0\n",
              "3    111111111        1           21  ...  0.000000  0.000000      0\n",
              "4    111111111        1           24  ...  0.000000  0.000000      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHqbQCKKFjHo",
        "colab_type": "text"
      },
      "source": [
        "Getting the data frame with sentences and saving tokens to the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTMwJaN0Essg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cols(input_df, col):\n",
        "  return input_df.groupby('sent_id')[col].apply(list).to_frame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC0ApJANkvmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_sent_lens(input_df, col='token'):\n",
        "  input_df['n_toks'] = input_df[col].apply(lambda x: len(x))\n",
        "  return input_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKIY6wegeyKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(input_df):\n",
        "  x = add_sent_lens(get_cols(input_df, 'token'))\n",
        "  for feature in feature_cols:\n",
        "    x = pd.merge(left=x, right=get_cols(input_df, feature),\n",
        "                 left_on='sent_id', right_on='sent_id')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzmv6p8heoJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4946ab8b-19b6-47d0-8289-e389c6219f63"
      },
      "source": [
        "train_raw = get_features(train_df)\n",
        "dev_raw = get_features(dev_df)\n",
        "\n",
        "train_raw.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-ad6cebfd0658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Woy2piMyik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "ad93efb8-a96f-480d-da8a-e820a89a0ee1"
      },
      "source": [
        "dev_raw.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>n_toks</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>arglex</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Police, had, previously, gone, to, home, wher...</td>\n",
              "      <td>12</td>\n",
              "      <td>[0.0625, 0.01875, 0.0, 0.03125, 0.0, 0.0147058...</td>\n",
              "      <td>[0.0, 0.05, 0.0, 0.40625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[CLEVELAND, —, Police, invstigating, domestic,...</td>\n",
              "      <td>31</td>\n",
              "      <td>[0.0, 0.0, 0.0625, 0.0, 0.02083333333333333, 0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.05, 0.0, 0....</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[police, reports, from, the, Columbus, suburb,...</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.0625, 0.038461538461538464, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.009615384615384616, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Westerville, Officers, Eric, Joering, ,, 39, ...</td>\n",
              "      <td>34</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[The, suspect, ,, 30-year, -, old, Quentin, Sm...</td>\n",
              "      <td>30</td>\n",
              "      <td>[0.0, 0.125, 0.0, 0.0, 0.0, 0.1527777777777778...</td>\n",
              "      <td>[0.0, 0.20833333333333331, 0.0, 0.0, 0.0, 0.06...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     token  ...                                             arglex\n",
              "sent_id                                                     ...                                                   \n",
              "1        [Police, had, previously, gone, to, home, wher...  ...               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "2        [CLEVELAND, —, Police, invstigating, domestic,...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "3        [police, reports, from, the, Columbus, suburb,...  ...                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "4        [Westerville, Officers, Eric, Joering, ,, 39, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "5        [The, suspect, ,, 30-year, -, old, Quentin, Sm...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z45vAbx6GNpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "bca0157b-19da-430e-aec4-4e88ad489fcf"
      },
      "source": [
        "train_y = get_cols(train_df, 'label')\n",
        "\n",
        "train_y.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 925",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-64aa068ae862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m925\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 925"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFczOPG1O0go",
        "colab_type": "text"
      },
      "source": [
        "## Encoding data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HxXV8BHMuA",
        "colab_type": "text"
      },
      "source": [
        "#### Encoding features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCS3v6NgWkvO",
        "colab_type": "text"
      },
      "source": [
        "Reading the glove embeddings from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61OlM1uZHtMr",
        "colab_type": "code",
        "outputId": "e1329546-b7b0-464e-cff1-35fb61bdc9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ab1jvz0H6hV",
        "colab_type": "code",
        "outputId": "c9eacdc7-c160-4829-ef71-b018a91f8ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "file_path = 'gdrive/My Drive/colab_projects/data/glove.6B.100d.txt'\n",
        "f = open(file_path)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOIFqkxbHJfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_X(x, feature_header, max_seq_len, embed_dim):\n",
        "  embedding_matrix = np.zeros([len(x),\n",
        "                               max_seq_len,\n",
        "                               embed_dim + len(feature_header)])\n",
        "  for row in x.itertuples():\n",
        "    sent_idx = row.Index - 1\n",
        "    for tok_idx in range(row.n_toks):\n",
        "      word = row.token[tok_idx]\n",
        "      embedding_matrix[sent_idx][tok_idx][:embed_dim] = embeddings_index.get(word,\n",
        "                                                                             np.random.randn(embed_dim))\n",
        "      for i, feature in enumerate(feature_header):\n",
        "        embedding_matrix[sent_idx][tok_idx][embed_dim + i] = getattr(row, feature)[tok_idx]\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPJx2gI0f5j",
        "colab_type": "code",
        "outputId": "dfafbcb1-a607-467e-f06f-22513afda007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_x = encode_X(train_raw, feature_cols, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)\n",
        "dev_x = encode_X(dev_raw, feature_cols, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)\n",
        "print(train_x.shape)\n",
        "print(dev_x.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21501, 35, 103)\n",
            "(3830, 35, 103)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nb1HZ4VGkDI",
        "colab_type": "text"
      },
      "source": [
        "#### Encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxuy8104Xpbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if N_CLASSES == 3:\n",
        "  label2idx = {\"O\": [1, 0, 0], \"B\": [0, 0, 1], \"I\": [0, 1, 0]}\n",
        "elif N_CLASSES == 2:\n",
        "  label2idx = {\"O\": [1, 0], \"B\": [0, 1], \"I\": [0, 1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6N07KeGoZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_y(y, label2idx, max_seq_len, n_classes):\n",
        "  if n_classes == 1:\n",
        "    labels = np.zeros([len(y), max_seq_len])\n",
        "  else:\n",
        "    labels = np.zeros([len(y), max_seq_len, n_classes])\n",
        "\n",
        "  for row in y.itertuples():\n",
        "    sent_idx = row.Index - 1\n",
        "    for tok_idx, label in enumerate(row.label):\n",
        "      labels[sent_idx][tok_idx] = label2idx[label]\n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5gi1Fjc1bP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d332670-20e2-41bd-b3d7-e945b9b92a08"
      },
      "source": [
        "y = encode_y(train_y, label2idx, MAX_SEQUENCE_LENGTH, N_CLASSES)\n",
        "y.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21501, 35, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR41hLh6FlZq",
        "colab_type": "code",
        "outputId": "608b9cb2-4db2-449a-81ea-62708b703b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "if class_weighting:\n",
        "  label2weight = {'O': o_weight, 'I': i_weight, 'B': b_weight}\n",
        "  sample_weight = encode_y(train_y, label2weight,\n",
        "                           MAX_SEQUENCE_LENGTH, n_classes=1)\n",
        "  print(sample_weight[2])\n",
        "else:\n",
        "  sample_weight = None"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.  6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 6.5 1.  1.  1.  1.  1.  1.  1.  1.\n",
            " 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQntrhwhW0Lo",
        "colab_type": "text"
      },
      "source": [
        "# 2. Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOR02X8PkI9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# def f1(y_true, y_pred):\n",
        "#   true_pos = tf.count_nonzero(y_true * y_pred)\n",
        "#   false_pos = tf.count_nonzero((y_true - 1) * y_pred)\n",
        "#   false_neg = tf.count_nonzero(y_true * (y_pred - 1))\n",
        "#   if true_pos == 0:\n",
        "#     return 0.0\n",
        "#   if false_pos == 0:\n",
        "#     return 0.0\n",
        "#   prec = true_pos / (true_pos + false_pos)\n",
        "#   if false_neg == 0:\n",
        "#     return 0.0\n",
        "#   return 2 * prec * rec / (prec + rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuzEvEcGI1xd",
        "colab_type": "code",
        "outputId": "13fe0edb-c4ac-45f8-9164-7b191fd3727e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(512, return_sequences=True),\n",
        "                        input_shape=(MAX_SEQUENCE_LENGTH,\n",
        "                                     EMBEDDING_DIM + len(feature_cols))))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(TimeDistributed(Dense(N_CLASSES, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy'],\n",
        "              sample_weight_mode='temporal')\n",
        "print(model.summary())"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_2 (Bidirection (None, 35, 1024)          2527232   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 35, 1024)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 35, 2)             2050      \n",
            "=================================================================\n",
            "Total params: 2,529,282\n",
            "Trainable params: 2,529,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-1dXcmbXCUc",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR09KbvE9V4l",
        "colab_type": "text"
      },
      "source": [
        "#### Training using all of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQH38939TCJ",
        "colab_type": "code",
        "outputId": "b52cac71-d32d-41df-d4e7-66a65bccee28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "history = model.fit(train_x, y,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    sample_weight=sample_weight)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 19350 samples, validate on 2151 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "19350/19350 [==============================] - 11s 578us/step - loss: 1.0690 - categorical_accuracy: 0.6585 - val_loss: 1.3461 - val_categorical_accuracy: 0.8378\n",
            "Epoch 2/10\n",
            "19350/19350 [==============================] - 4s 209us/step - loss: 1.0185 - categorical_accuracy: 0.7237 - val_loss: 1.6981 - val_categorical_accuracy: 0.7876\n",
            "Epoch 3/10\n",
            "19350/19350 [==============================] - 4s 208us/step - loss: 1.0037 - categorical_accuracy: 0.7248 - val_loss: 1.2355 - val_categorical_accuracy: 0.7715\n",
            "Epoch 4/10\n",
            "19350/19350 [==============================] - 4s 209us/step - loss: 0.9786 - categorical_accuracy: 0.6998 - val_loss: 1.3116 - val_categorical_accuracy: 0.7513\n",
            "Epoch 5/10\n",
            "19350/19350 [==============================] - 4s 210us/step - loss: 0.9561 - categorical_accuracy: 0.6807 - val_loss: 1.2460 - val_categorical_accuracy: 0.6171\n",
            "Epoch 6/10\n",
            "19350/19350 [==============================] - 4s 209us/step - loss: 0.8907 - categorical_accuracy: 0.6798 - val_loss: 1.4505 - val_categorical_accuracy: 0.6755\n",
            "Epoch 7/10\n",
            "19350/19350 [==============================] - 4s 205us/step - loss: 0.7871 - categorical_accuracy: 0.7426 - val_loss: 1.4483 - val_categorical_accuracy: 0.7340\n",
            "Epoch 8/10\n",
            "19350/19350 [==============================] - 4s 208us/step - loss: 0.6660 - categorical_accuracy: 0.7906 - val_loss: 1.9426 - val_categorical_accuracy: 0.7148\n",
            "Epoch 9/10\n",
            "19350/19350 [==============================] - 4s 208us/step - loss: 0.5365 - categorical_accuracy: 0.8127 - val_loss: 2.3495 - val_categorical_accuracy: 0.8285\n",
            "Epoch 10/10\n",
            "19350/19350 [==============================] - 4s 207us/step - loss: 0.4385 - categorical_accuracy: 0.8136 - val_loss: 2.5558 - val_categorical_accuracy: 0.7494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLY5LLDu-aGd",
        "colab_type": "text"
      },
      "source": [
        "# 4. Getting predictions for development data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxSwb0CM_Gnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model.predict(dev_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaJ4lsXhK8SV",
        "colab_type": "text"
      },
      "source": [
        "From one-hot encoding to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLVudMQZBm_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c9b46e-1d89-4e88-debe-0a22b1a687b7"
      },
      "source": [
        "y_hat = y_hat.reshape(-1, N_CLASSES).argmax(axis=1).reshape(len(dev_x), MAX_SEQUENCE_LENGTH)\n",
        "y_hat.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3830, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtwvGRVyLFSP",
        "colab_type": "text"
      },
      "source": [
        "Mapping the predictions to the corresponding indeces in the dev data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiKKHORD_MtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_vector(x, y_hat):\n",
        "  labels_vector = []\n",
        "  for row in x.itertuples():\n",
        "    sent_idx = row.Index - 1\n",
        "    for tok_idx in range(row.n_toks):\n",
        "      if y_hat[sent_idx][tok_idx] == 0:\n",
        "        label = \"O\"\n",
        "      elif y_hat[sent_idx][tok_idx] == 1:\n",
        "        label = \"I\"\n",
        "      else:\n",
        "        label = \"B\"\n",
        "      labels_vector.append(label)\n",
        "  return labels_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXk0goGJIN-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels_column = get_labels_vector(dev_raw, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxkp3Uu6LdcT",
        "colab_type": "text"
      },
      "source": [
        "Concatenation of the original dev data frame and the prediction vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1bCqoG2I-lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df = pd.concat([dev_df, pd.DataFrame(predicted_labels_column, columns=[\"label\"])], axis=1, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xEvfqvyLlxk",
        "colab_type": "text"
      },
      "source": [
        "Overview of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReEg19naJJBd",
        "colab_type": "code",
        "outputId": "962d7bd8-88c4-417c-c1f5-279c511b8ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "result_df.head()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token_start</th>\n",
              "      <th>token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>arglex</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Police</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>had</td>\n",
              "      <td>0.01875</td>\n",
              "      <td>0.05000</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>previously</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>gone</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>730081389</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>to</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_id  token_start  ...  negative arglex  label\n",
              "0    730081389        1            0  ...   0.00000      0      O\n",
              "1    730081389        1            7  ...   0.05000      0      O\n",
              "2    730081389        1           11  ...   0.00000      0      O\n",
              "3    730081389        1           22  ...   0.40625      0      O\n",
              "4    730081389        1           27  ...   0.00000      0      O\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ETlCuf3Jj29",
        "colab_type": "code",
        "outputId": "bc5b72f9-a38d-4345-e72b-f0d8adae5cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "result_df[\"label\"].value_counts()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O    54005\n",
              "I    13168\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzHxnLwkMytk",
        "colab_type": "text"
      },
      "source": [
        "Saving data frame to a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9fMlY7BMyWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(outfile, mode='wb') as f:\n",
        "  for comment in dev_comments:\n",
        "    f.write(comment)\n",
        "\n",
        "result_df.to_csv(path_or_buf=outfile, sep='\\t',\n",
        "                 mode='a', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}