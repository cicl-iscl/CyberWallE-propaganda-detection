{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MergeTrainAndDev.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu2TzwBBbXOt",
        "colab_type": "text"
      },
      "source": [
        "Acknowlegements: Thanks to Verena (and Maxim) for much of this lovely code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2xeJJ73Z7aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXQHvVuUZgcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_comments(filename, url=True):\n",
        "    if url:\n",
        "        comments = []\n",
        "        with urllib.request.urlopen(filename) as f:\n",
        "            for line in f:\n",
        "                if line.startswith(b'#'):\n",
        "                    comments.append(line.decode(\"utf-8\"))\n",
        "                else:\n",
        "                    break\n",
        "        return comments\n",
        "    with open(filename, 'r', encoding='utf8') as f:\n",
        "        commentiter = takewhile(lambda s: s.startswith('#'), f)\n",
        "        comments = list(commentiter)\n",
        "    return comments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0axNlxoyWLKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train-improved-sentiwordnet-arguingfullindiv-pos.tsv?token=AFDEFD4F7VOZTUSCLUDLSUC6LEXMC'\n",
        "DEV_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/dev-improved-sentiwordnet-arguingfullindiv-pos.tsv?token=AFDEFD3UUERAVPLXIMU52MS6LEXSI'\n",
        "DEV_LABELS_URL = 'https://raw.githubusercontent.com/cicl-iscl/CyberWallE/master/data/train%2Bdev-improved.tsv?token=AFDEFD2UDJVAC5JW2NOOPZK6LKNCS'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feVeu1ioZS7V",
        "colab_type": "code",
        "outputId": "ab26f74c-0c4e-48a8-9fa3-60d687fd277e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "comments = get_comments(TRAIN_URL)\n",
        "train_df = pd.read_csv(TRAIN_URL, sep='\\t', skiprows=len(comments), quoting=3)\n",
        "train_input = train_df.groupby('sent_id')['token'].apply(list).to_frame()\n",
        "print(train_df.head())\n",
        "print(train_input.head())\n",
        "print(list(train_df.columns))\n",
        "print(train_df.shape[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document_id  sent_id  token_start  token_end  ... PUNCT SYM  VERB  X\n",
            "0    111111111        1            0          4  ...     0   0     0  0\n",
            "1    111111111        1            5         11  ...     0   0     0  0\n",
            "2    111111111        1           12         20  ...     0   0     0  0\n",
            "3    111111111        1           21         23  ...     0   0     0  0\n",
            "4    111111111        1           24         34  ...     0   0     0  0\n",
            "\n",
            "[5 rows x 24 columns]\n",
            "                                                     token\n",
            "sent_id                                                   \n",
            "1        [Next, plague, outbreak, in, Madagascar, could...\n",
            "2        [Geneva, -, The, World, Health, Organisation, ...\n",
            "3        [\", The, next, transmission, could, be, more, ...\n",
            "4        [An, outbreak, of, both, bubonic, plague, ,, w...\n",
            "5        [has, killed, more, than, 200, people, in, the...\n",
            "['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']\n",
            "401288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuwkTZRDbUkK",
        "colab_type": "code",
        "outputId": "60e6c94d-4502-4e38-a07e-ebb0fa3523bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "#delete 730081389\n",
        "comments = get_comments(DEV_URL)\n",
        "dev_df = pd.read_csv(DEV_URL, sep='\\t', skiprows=len(comments), quoting=3)\n",
        "dev_input = dev_df.groupby('sent_id')['token'].apply(list).to_frame()\n",
        "print(dev_df.head())\n",
        "print(dev_input.head())\n",
        "print(list(dev_df.columns))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document_id  sent_id  token_start  token_end  ... PUNCT  SYM  VERB  X\n",
            "0    730081389        1            0          6  ...     0    0     0  0\n",
            "1    730081389        1            7         10  ...     0    0     1  0\n",
            "2    730081389        1           11         21  ...     0    0     0  0\n",
            "3    730081389        1           22         26  ...     0    0     1  0\n",
            "4    730081389        1           27         29  ...     0    0     0  0\n",
            "\n",
            "[5 rows x 23 columns]\n",
            "                                                     token\n",
            "sent_id                                                   \n",
            "1        [Police, had, previously, gone, to, home, wher...\n",
            "2        [CLEVELAND, â€”, Police, invstigating, domestic,...\n",
            "3        [police, reports, from, the, Columbus, suburb,...\n",
            "4        [Westerville, Officers, Eric, Joering, ,, 39, ...\n",
            "5        [The, suspect, ,, 30-year, -, old, Quentin, Sm...\n",
            "['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3u_lxA5CJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c0b6c85c-d2c1-4591-8acc-72254c768fd2"
      },
      "source": [
        "dev_df = dev_df[dev_df.document_id != 730081389]\n",
        "print(dev_df.head())\n",
        "print(dev_df.shape[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     document_id  sent_id  token_start  token_end  ... PUNCT  SYM  VERB  X\n",
            "347    730093263       22            0          7  ...     0    0     0  0\n",
            "348    730093263       22            7          9  ...     0    0     0  0\n",
            "349    730093263       22           10         21  ...     0    0     0  0\n",
            "350    730093263       22           22         27  ...     0    0     0  0\n",
            "351    730093263       22           27         28  ...     1    0     0  0\n",
            "\n",
            "[5 rows x 23 columns]\n",
            "66826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7jgOZbK2fLI",
        "colab_type": "code",
        "outputId": "23bb58ac-4b81-4a4d-ede3-398e010fc824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dev_labels_df = pd.read_csv(DEV_LABELS_URL, sep='\\t', skiprows=1, quoting=3)\n",
        "print(dev_labels_df.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document_id  sent_id  token_start  token_end        token label\n",
            "0    730093263        1            0          7      America     O\n",
            "1    730093263        1            7          9           's     O\n",
            "2    730093263        1           10         21  Immigration     O\n",
            "3    730093263        1           22         27        Voice     O\n",
            "4    730093263        1           27         28            .     O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBEcWMJf6JnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4a63923a-46ae-4b35-9780-deedc746a381"
      },
      "source": [
        "result_df = dev_df.merge(dev_labels_df, how='inner', left_on=['document_id', 'token_start'], right_on=['document_id', 'token_start'])\n",
        "print(result_df.head())\n",
        "print(list(result_df.columns))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document_id  sent_id_x  token_start  ...  token_end_y      token_y  label\n",
            "0    730093263         22            0  ...            7      America      O\n",
            "1    730093263         22            7  ...            9           's      O\n",
            "2    730093263         22           10  ...           21  Immigration      O\n",
            "3    730093263         22           22  ...           27        Voice      O\n",
            "4    730093263         22           27  ...           28            .      O\n",
            "\n",
            "[5 rows x 27 columns]\n",
            "['document_id', 'sent_id_x', 'token_start', 'token_end_x', 'token_x', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X', 'sent_id_y', 'token_end_y', 'token_y', 'label']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpMK78vCeXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df = result_df.drop(columns=['sent_id_y', 'token_end_y', 'token_y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYAeLFVD6_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ecc36521-39ab-4ef7-8aea-3b7063432891"
      },
      "source": [
        "result_df = result_df.rename(columns={\"sent_id_x\": \"sent_id\", \"token_end_x\": \"token_end\", \"token_x\":\"token\"})\n",
        "print(list(result_df.columns))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X', 'label']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o55gJCqoEqVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_df_1 = result_df[['document_id', 'sent_id', 'token_start', 'token_end', 'token', 'label', 'positive', 'negative', 'arglex_any', 'ADJ', 'ADP', 'ADV', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SYM', 'VERB', 'X']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJwRVCcfFS87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "901c7530-b9f2-43c9-d2ce-c3c98850211b"
      },
      "source": [
        "result_df_1.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token_start</th>\n",
              "      <th>token_end</th>\n",
              "      <th>token</th>\n",
              "      <th>label</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>arglex_any</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>ADP</th>\n",
              "      <th>ADV</th>\n",
              "      <th>CCONJ</th>\n",
              "      <th>DET</th>\n",
              "      <th>INTJ</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>NUM</th>\n",
              "      <th>PART</th>\n",
              "      <th>PRON</th>\n",
              "      <th>PROPN</th>\n",
              "      <th>PUNCT</th>\n",
              "      <th>SYM</th>\n",
              "      <th>VERB</th>\n",
              "      <th>X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>730093263</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>America</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>730093263</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>'s</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>730093263</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>Immigration</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>730093263</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>27</td>\n",
              "      <td>Voice</td>\n",
              "      <td>O</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>730093263</td>\n",
              "      <td>22</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sent_id  token_start  token_end  ... PUNCT SYM  VERB  X\n",
              "0    730093263       22            0          7  ...     0   0     0  0\n",
              "1    730093263       22            7          9  ...     0   0     0  0\n",
              "2    730093263       22           10         21  ...     0   0     0  0\n",
              "3    730093263       22           22         27  ...     0   0     0  0\n",
              "4    730093263       22           27         28  ...     1   0     0  0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQs0u3HocDx7",
        "colab_type": "code",
        "outputId": "a13e9b93-9885-498c-e4c9-eca763dfbc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "frames = [train_df, result_df_1]\n",
        "train_dev_df = pd.concat(frames)\n",
        "train_dev_df.shape[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUfRsnUlGjr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = train_dev_df.to_csv(\"train_dev_set.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvOrX3LFHtXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"train_dev_set.tsv\") "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}